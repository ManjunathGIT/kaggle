{
 "metadata": {
  "name": "model4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "# SAMPLE SUBMISSION TO THE BIG DATA HACKATHON 13-14 April 2013 'Influencers in a Social Network'\n",
      "# .... more info on Kaggle and links to go here\n",
      "#\n",
      "# written by Ferenc Husz\u00e1r, PeerIndex\n",
      "\n",
      "from sklearn import linear_model\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import svm\n",
      "from sklearn import preprocessing\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import auc_score\n",
      "import numpy as np\n",
      "\n",
      "###########################\n",
      "# LOADING TRAINING DATA\n",
      "###########################\n",
      "\n",
      "trainfile = open('train.csv')\n",
      "header = trainfile.next().rstrip().split(',')\n",
      "\n",
      "y_train = []\n",
      "X_train_A = []\n",
      "X_train_B = []\n",
      "\n",
      "for line in trainfile:\n",
      "    splitted = line.rstrip().split(',')\n",
      "    label = int(splitted[0])\n",
      "    A_features = [float(item) for item in splitted[1:12]]\n",
      "    B_features = [float(item) for item in splitted[12:]]\n",
      "    y_train.append(label)\n",
      "    X_train_A.append(A_features)\n",
      "    X_train_B.append(B_features)\n",
      "trainfile.close()\n",
      "\n",
      "y_train = np.array(y_train)\n",
      "X_train_A = np.array(X_train_A)\n",
      "X_train_B = np.array(X_train_B)\n",
      "\n",
      "###########################\n",
      "# EXAMPLE BASELINE SOLUTION USING SCIKIT-LEARN\n",
      "#\n",
      "# using scikit-learn LogisticRegression module without fitting intercept\n",
      "# to make it more interesting instead of using the raw features we transform them logarithmically\n",
      "# the input to the classifier will be the difference between transformed features of A and B\n",
      "# the method roughly follows this procedure, except that we already start with pairwise data\n",
      "# http://fseoane.net/blog/2012/learning-to-rank-with-scikit-learn-the-pairwise-transform/\n",
      "###########################\n",
      "\n",
      "def transform_features(x):\n",
      "    #return np.log(1+x)\n",
      "    return preprocessing.MinMaxScaler().fit_transform(np.log(1+x))\n",
      "\n",
      "X = transform_features(X_train_A) - transform_features(X_train_B)\n",
      "X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(X, y_train, test_size=0.2, random_state=0)\n",
      "model = linear_model.LogisticRegression(fit_intercept=False)\n",
      "#model = RandomForestClassifier(n_estimators=150, min_samples_split=2, n_jobs=-1)\n",
      "#model = svm.SVC()\n",
      "model.fit(X_train,y_train)\n",
      "# compute AuC score on the training data (BTW this is kind of useless due to overfitting, but hey, this is only an example solution)\n",
      "p_cv = model.predict_proba(X_cv)\n",
      "print p_cv\n",
      "p_cv = p_cv[:,1:2]\n",
      "print p_cv\n",
      "print 'AuC score on CV data:',auc_score(y_cv,p_cv.T)\n",
      "\n",
      "\n",
      "###########################\n",
      "# READING TEST DATA\n",
      "###########################\n",
      "\n",
      "testfile = open('test.csv')\n",
      "#ignore the test header\n",
      "testfile.next()\n",
      "\n",
      "X_test_A = []\n",
      "X_test_B = []\n",
      "for line in testfile:\n",
      "    splitted = line.rstrip().split(',')\n",
      "    A_features = [float(item) for item in splitted[0:11]]\n",
      "    B_features = [float(item) for item in splitted[11:]]\n",
      "    X_test_A.append(A_features)\n",
      "    X_test_B.append(B_features)\n",
      "testfile.close()\n",
      "\n",
      "X_test_A = np.array(X_test_A)\n",
      "X_test_B = np.array(X_test_B)\n",
      "\n",
      "# transform features in the same way as for training to ensure consistency\n",
      "X_test = transform_features(X_test_A) - transform_features(X_test_B)\n",
      "# compute probabilistic predictions\n",
      "p_test = model.predict_proba(X_test)\n",
      "#only need the probability of the 1 class\n",
      "p_test = p_test[:,1:2]\n",
      "\n",
      "###########################\n",
      "# WRITING SUBMISSION FILE\n",
      "###########################\n",
      "predfile = open('predictions.csv','w+')\n",
      "\n",
      "print >>predfile,','.join(header)\n",
      "for line in np.concatenate((p_test,X_test_A,X_test_B),axis=1):\n",
      "    print >>predfile, ','.join([str(item) for item in line])\n",
      "\n",
      "predfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.63605156]\n",
        " [ 0.92427498]\n",
        " [ 0.93626292]\n",
        " ..., \n",
        " [ 0.9411881 ]\n",
        " [ 0.91905727]\n",
        " [ 0.69768768]]\n",
        "AuC score on CV data: 0.866723574331\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}